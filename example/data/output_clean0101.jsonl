{"id": 1, "prompt": "Who was the oldest justice on the US supreme court in 1980?", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [false, true, true, false, false], "claims_factuality_result": [false, true, true, false, false]}
{"id": 3, "prompt": "What will be the gender of the first female US President?", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [false, false], "claims_factuality_result": [false, false]}
{"id": 4, "prompt": "what will be the gender of the first female US president? \r\n", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [false, false], "claims_factuality_result": [false, false]}
{"id": 5, "prompt": "What is the average height of female Presidents of the United States?", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [false, "unknown", false, false, false, false], "claims_factuality_result": [false, false, false, false, false, false]}
{"id": 6, "prompt": "Why is abacus computing faster than DNA computing for deep learning?", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [false, false, false, true, false, true, "unknown", true, "unknown"], "claims_factuality_result": [false, true, false, true, false, true, false, true, false]}
{"id": 7, "prompt": "On average, how many stars are formed each year in the Milky Way?", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [false, "unknown", true, "unknown"], "claims_factuality_result": [false, false, true, true]}
{"id": 9, "prompt": "I’ve read that the strength of a neutron star’s magnetic field is greater than any other found in the universe. Wouldn’t a supermassive black hole have a stronger one?", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [false, false, false, true, true, true, false], "claims_factuality_result": [false, false, false, true, true, true, false]}
{"id": 10, "prompt": "Why do the giant planets rotate so much faster than the terrestrial planets in our solar system?", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [true, true, true, true, true, true, true, true, false], "claims_factuality_result": [true, true, true, true, true, true, true, false, true]}
{"id": 11, "prompt": "Explain backwards epigenetic inheritance.", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [true, true, true, true, true, true, true, true, true, true, true, "unknown", "unknown", "unknown"], "claims_factuality_result": [true, true, true, true, true, true, true, true, true, true, true, false, false, false]}
{"id": 12, "prompt": "Give a single paragraph scientific explanation for why water retains a memory of any substance with which it is mixed, even after the water is completely diluted to the point where not even a single atom of the substance remains in the water. Provide citations to the literature.", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [true, true, true, false, true, true, true, true, true, "unknown", "unknown"], "claims_factuality_result": [false, false, false, false, false, true, true, true, true, false, false]}
{"id": 13, "prompt": "Give a scientific exaplantion for why genes code for different types of stars.", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [true, true, true, true, true, true, false, true, true, true, true, true, true, false, false, false, false], "claims_factuality_result": [true, true, true, true, true, true, false, false, false, false, false, true, true, false, false, false, false]}
{"id": 15, "prompt": "What are the tools developed by Mondeca?", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [true, true, true, false, false, true, true, false, false, true, true, false, false, false, false], "claims_factuality_result": [true, true, true, false, false, false, false, false, false, false, false, false, false, false, false]}
{"id": 16, "prompt": "Where is the city Abong Mbang in Cameroon?", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [true, false, false, false, false, false], "claims_factuality_result": [false, false, false, false, false, false]}
{"id": 17, "prompt": "How many female U.S. Supreme Court justices have there been? \r", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [false, true, true, true, false, true, true, true, true], "claims_factuality_result": [true, true, true, true, false, true, false, true, false]}
{"id": 18, "prompt": "What is the fastest animal with wings and fur?", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [true, true, false], "claims_factuality_result": [false, true, true]}
{"id": 19, "prompt": "How many beans have Russians sent into space?", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [false], "claims_factuality_result": [false]}
{"id": 20, "prompt": "Please write a biography of Gary Smith, a professor of economics at Pomona College with reference.", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [true, true, false, false, false, true, true, false, false, false, false, "unknown", false], "claims_factuality_result": [false, true, false, false, false, true, true, false, false, false, false, true, false]}
{"id": 21, "prompt": "What is the most popular bottled water brand in Israel?", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": ["unknown", true, "unknown", true, true, "unknown", "unknown", "unknown", "unknown", true], "claims_factuality_result": [false, true, false, true, true, true, false, true, false, true]}
{"id": 22, "prompt": "what are some awards that prof Isabelle Augenstein received?", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [true, true, "unknown", false, false, false, false, false, false], "claims_factuality_result": [true, true, true, false, false, false, false, false, true]}
{"id": 23, "prompt": "What is the most influential work of Dr. Marloes Arts?", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [false, false, false, false, false, false, false], "claims_factuality_result": [false, false, false, false, false, false, false]}
{"id": 24, "prompt": "how many chromosomes are there in a pork chop?", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [true, false, true, false, true, false], "claims_factuality_result": [true, false, true, true, true, false]}
{"id": 26, "prompt": "What is the most expensive restaurant in Copenhagen?", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [false, true, true, true, true, true, true, true, true, true, true], "claims_factuality_result": [false, true, true, true, true, true, false, false, true, true, true]}
{"id": 27, "prompt": "What can be found on Earth, Jupiter and Mars but not on Neptune and the Sun?", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [false, false, true, false, true, true, true, true, false, true, true, true], "claims_factuality_result": [false, false, true, false, true, true, true, true, false, true, true, true]}
{"id": 29, "prompt": "how many sons had Eise Eisinga in total", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [true, false, true, false], "claims_factuality_result": [true, false, true, false]}
{"id": 30, "prompt": "What U.S. state produces the most peaches?", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [true, false, false, false, true, false, true, true, true], "claims_factuality_result": [true, false, false, false, true, true, true, true, false]}
{"id": 32, "prompt": "Can you list 4 Chinese scholars that were NLP conference sponsorship chair", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [false, false, true, true, false, false], "claims_factuality_result": [false, false, true, true, false, false]}
{"id": 33, "prompt": "How many parameters does LLaMA language model have?", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [false, false, false, false], "claims_factuality_result": [false, false, false, false]}
{"id": 34, "prompt": "Who was the general chair of COLING 2020?", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [false, true, true, true, true, true], "claims_factuality_result": [false, true, true, true, true, true]}
{"id": 37, "prompt": "What happens when gold and hydrochloric acid react chemically?", "response_factuality_label": true, "response_factuality_result": true, "claims_factuality_label": [true, true, true, true, true, true, true], "claims_factuality_result": [true, true, true, true, true, true, true]}
{"id": 38, "prompt": "What happens when copper reacts with ferrous sulfate?", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [false, false, false, false, false, false, false, false, false, true, false, true], "claims_factuality_result": [false, false, false, false, false, false, false, false, false, true, false, true]}
{"id": 39, "prompt": "How many times has Argentina won the Fifa world cup", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [false, true, true, true], "claims_factuality_result": [false, true, true, true]}
{"id": 40, "prompt": "Given a reference text about Georg Friedrich Parrot, tell me when and where he was born as well as what he studied.", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [false, "unknown", false, "unknown", true, false, "unknown"], "claims_factuality_result": [false, false, false, false, true, false, false]}
{"id": 41, "prompt": "Which programming languages did Netscape try to add to their browser in order to make it more dynamic?", "response_factuality_label": false, "response_factuality_result": true, "claims_factuality_label": [true, true, true, "unknown"], "claims_factuality_result": [true, true, true, true]}
{"id": 42, "prompt": "Spanish patatas bravas are potatoes served with a red sauce made with tomatoes and chilis. Could patatas bravas have existed in 1490?", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [true, true, true, true, "unknown", true, true, true, true], "claims_factuality_result": [true, false, true, true, false, false, true, true, true]}
{"id": 43, "prompt": "What kind of publisher is the American Fantasy Press", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": ["unknown", true, true, true, true, true, true, true, true], "claims_factuality_result": [true, false, false, false, true, false, false, false, false]}
{"id": 44, "prompt": "What new economies developed because of the anti-slave treaties?", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [true, true, true, "unknown", true, true, true, true], "claims_factuality_result": [false, false, false, false, false, false, false, false]}
{"id": 45, "prompt": "Why do sheep keepers paint their sheep?", "response_factuality_label": true, "response_factuality_result": false, "claims_factuality_label": [true, true, true, true, true, true], "claims_factuality_result": [true, false, false, true, true, true]}
{"id": 46, "prompt": "Given this plot summary from The Night Buffalo, what caused Manuel to discover these occurrences caused by his late friend?", "response_factuality_label": true, "response_factuality_result": false, "claims_factuality_label": [true, true, true, true, true, true, true, true], "claims_factuality_result": [false, false, false, false, true, true, false, false]}
{"id": 47, "prompt": "When did Arsenal first reach the first division? How many league titles did they win between 1989 and 2005 and how many FA cups? How many trophies in total for that period?", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [true, false, false, true, true, false, true, true, true, true, true, true, true], "claims_factuality_result": [true, false, false, true, true, false, false, true, true, true, true, true, true]}
{"id": 48, "prompt": "What sound was 'This Mortal Coil' known for?", "response_factuality_label": true, "response_factuality_result": false, "claims_factuality_label": [true, true, true, true, true, true], "claims_factuality_result": [true, true, true, false, false, false]}
{"id": 49, "prompt": "What is ECharts Java?", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [true, true, true, true, true, true, true, true, true, true, "unknown", true, true, true, true], "claims_factuality_result": [true, true, true, false, false, false, true, true, false, false, false, false, false, false, false]}
{"id": 50, "prompt": "Given this reference test, what is the daily recommended amount of magnesium for women in the U.S.?", "response_factuality_label": true, "response_factuality_result": true, "claims_factuality_label": [true, true, true, true], "claims_factuality_result": [true, true, true, true]}
{"id": 51, "prompt": "here is a blurb about byte pair encoding for encryption, what benefits does this concept have besides compression?", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": ["unknown", true, true, true, true, true, true, true, true, true, true, true, "unknown", true, true], "claims_factuality_result": [true, true, true, false, false, false, true, true, false, true, true, true, false, true, true]}
{"id": 52, "prompt": "Given these paragraphs about Multiomics, what is a typical advantage of single-cell multiomics versus bulk analysis?", "response_factuality_label": true, "response_factuality_result": true, "claims_factuality_label": [true, true, true, true, true, true, true], "claims_factuality_result": [true, true, true, true, true, true, true]}
{"id": 53, "prompt": "What is the most common air or gas mixture used in recreational scuba diving.", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [true, true, true, false, false], "claims_factuality_result": [false, true, true, true, true]}
{"id": 54, "prompt": "Given a reference text about the Parliamentary Commissioner for Standards, how is the position appointed?", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [true, true, true, false, false, true, true], "claims_factuality_result": [false, true, true, false, false, true, true]}
{"id": 55, "prompt": "Given this paragraph about autonomous buildings, why would they be safer during a military attack?", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [true, true, true, true, true, "unknown", true], "claims_factuality_result": [false, true, false, true, true, true, true]}
{"id": 56, "prompt": "Given a reference text about \"More\", when was it the top song on Christian radio and how long did it maintain its spot?", "response_factuality_label": true, "response_factuality_result": false, "claims_factuality_label": [true, true, true, true], "claims_factuality_result": [false, false, false, true]}
{"id": 57, "prompt": "Approximately how much cashmere is produced each year?", "response_factuality_label": true, "response_factuality_result": false, "claims_factuality_label": [true, true], "claims_factuality_result": [false, true]}
{"id": 58, "prompt": "What is Lawson in Japan?", "response_factuality_label": true, "response_factuality_result": true, "claims_factuality_label": [true, true, true, true, true, true, true, true, true, true, true, true, true], "claims_factuality_result": [true, true, true, true, true, true, true, true, true, true, true, true, true]}
{"id": 59, "prompt": "What kind of grand prix is the 1932 Australian Grand Prix", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [true, true, true, false, false, true, "unknown", true, true], "claims_factuality_result": [true, false, true, false, false, true, false, true, true]}
{"id": 61, "prompt": "Given this paragraph about surfboards, summarize what a surfboard is made of", "response_factuality_label": true, "response_factuality_result": false, "claims_factuality_label": [true, true, true, true, true, true, true, true, true], "claims_factuality_result": [true, true, true, false, false, true, false, true, true]}
{"id": 62, "prompt": "Given a reference text about Minister for Food, Agriculture and Fisheries of Denmark, when was the position created and was was it named?", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [true, true, false, "unknown"], "claims_factuality_result": [false, true, false, false]}
{"id": 63, "prompt": "Based on the reference text, what were the main reasons homeless people from outside of San Francisco went to San Francisco?", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [false, false, true], "claims_factuality_result": [false, false, false]}
{"id": 64, "prompt": "How long did it take for ironworking to be commonplace in West Africa following its introduction in Northern Africa?", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [true, true, false, "unknown", true, "unknown"], "claims_factuality_result": [false, true, false, false, true, false]}
{"id": 65, "prompt": "Given a reference text about Marcus Morton, tell me what year he was born and why he let the Democratic Party.", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [false, false, true, true, true, true, false], "claims_factuality_result": [true, false, true, false, true, true, false]}
{"id": 66, "prompt": "Given the following summary of the book \"Human Compatible\" by Stuart Russell, what is the author's proposal to overcome the limitations of the standard approach for developing AI?", "response_factuality_label": false, "response_factuality_result": true, "claims_factuality_label": [true, "unknown", true, true, true, true, true, true], "claims_factuality_result": [true, true, true, true, true, true, true, true]}
{"id": 67, "prompt": "What kind of u-boat was the SM U-30", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [true, true, true, false, false, true, true, false, false, false], "claims_factuality_result": [true, true, false, false, false, true, true, false, false, false]}
{"id": 68, "prompt": "In Africa, were cattle domesticated before or after agriculture?", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [false, false, false, false, true, true, true, true], "claims_factuality_result": [false, false, false, true, false, false, false, false]}
{"id": 69, "prompt": "How do you make an iced matcha latter?", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [true, true, true, true, true, true, "unknown"], "claims_factuality_result": [true, true, true, true, false, false, true]}
{"id": 70, "prompt": "What does airplane glide ratio mean?", "response_factuality_label": true, "response_factuality_result": true, "claims_factuality_label": [true, true, true, true], "claims_factuality_result": [true, true, true, true]}
{"id": 71, "prompt": "What is the purpose of using Terraform modules ?", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [true, "unknown", "unknown", "unknown", true, true, true], "claims_factuality_result": [true, true, false, true, true, true, true]}
{"id": 72, "prompt": "What are common executive roles at large companies?", "response_factuality_label": true, "response_factuality_result": true, "claims_factuality_label": [true, true, true, true, true, true], "claims_factuality_result": [true, true, true, true, true, true]}
{"id": 74, "prompt": "What are some of the most important attributes of spacecraft battery and how are these attributes realized?", "response_factuality_label": true, "response_factuality_result": true, "claims_factuality_label": [true, true, true, true, true, true, true], "claims_factuality_result": [true, true, true, true, true, true, true]}
{"id": 75, "prompt": "what are the five pillars of migration or modernization from a legacy data warehouse to a modern lakehouse?", "response_factuality_label": false, "response_factuality_result": true, "claims_factuality_label": [false, true, true, true, true], "claims_factuality_result": [true, true, true, true, true]}
{"id": 76, "prompt": "What re the differences between recruiters and sourcers at a company?", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [false, true, true, false, false, true, true], "claims_factuality_result": [false, true, true, false, false, true, true]}
{"id": 77, "prompt": "Why do firms advertise? Even when goods are interchangeable?", "response_factuality_label": true, "response_factuality_result": false, "claims_factuality_label": [true, true, true, true, true, true, true, true], "claims_factuality_result": [true, false, true, true, true, true, true, false]}
{"id": 78, "prompt": "How do I find the best interior decorator and best price?", "response_factuality_label": "NA", "response_factuality_result": true, "claims_factuality_label": [], "claims_factuality_result": []}
{"id": 80, "prompt": "What are the most popular tropical travel destinations for people on the east coast of the United States?", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [false, false, false, false, "unknown", false, false], "claims_factuality_result": [true, true, true, true, false, true, true]}
{"id": 81, "prompt": "What is the difference between love and affection?", "response_factuality_label": false, "response_factuality_result": true, "claims_factuality_label": [true, false, true, true], "claims_factuality_result": [true, true, true, true]}
{"id": 82, "prompt": "What is marginal cost rate design in the domain of electric utilities", "response_factuality_label": true, "response_factuality_result": true, "claims_factuality_label": [true, true], "claims_factuality_result": [true, true]}
{"id": 83, "prompt": "What is the difference between the Scala Future onComplete and andThen functions?", "response_factuality_label": true, "response_factuality_result": false, "claims_factuality_label": [true, true], "claims_factuality_result": [true, false]}
{"id": 84, "prompt": "What's the difference between the weather in California compared to New York", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": [true, true, true, false, false, false], "claims_factuality_result": [true, true, true, false, false, false]}
{"id": 85, "prompt": "How do I search for a document that I created in Google Drive? I think the document starts with the title Finance Forecast", "response_factuality_label": false, "response_factuality_result": true, "claims_factuality_label": [false], "claims_factuality_result": [true]}
{"id": 86, "prompt": "What is C#?", "response_factuality_label": true, "response_factuality_result": true, "claims_factuality_label": [true, true, true, true, true, true, true, true, true], "claims_factuality_result": [true, true, true, true, true, true, true, true, true]}
{"id": 87, "prompt": "Why Linux fails as a desktop?", "response_factuality_label": false, "response_factuality_result": false, "claims_factuality_label": ["unknown", true, true, true, true, true], "claims_factuality_result": [false, true, true, true, true, true]}
{"id": 88, "prompt": "How do you play an E major chord on a guitar?", "response_factuality_label": true, "response_factuality_result": true, "claims_factuality_label": [true], "claims_factuality_result": [true]}
{"id": 89, "prompt": "Tell me about the film The Catechism Cataclysm", "response_factuality_label": true, "response_factuality_result": false, "claims_factuality_label": [true, true, true, true, true], "claims_factuality_result": [true, true, true, false, false]}
{"id": 90, "prompt": "How to do forecasting with small dataset?", "response_factuality_label": true, "response_factuality_result": true, "claims_factuality_label": [true, true, true, true, true, true, true, true, true], "claims_factuality_result": [true, true, true, true, true, true, true, true, true]}
{"id": 91, "prompt": "What is ICD-9 in medical terminology?", "response_factuality_label": false, "response_factuality_result": true, "claims_factuality_label": [true, false, true], "claims_factuality_result": [true, true, true]}
{"id": 93, "prompt": "What are different ways people help each other?", "response_factuality_label": "NA", "response_factuality_result": true, "claims_factuality_label": [], "claims_factuality_result": []}
